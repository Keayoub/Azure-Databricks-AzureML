# Azure Databricks + Key Vault Architecture Guide

## Executive Summary

This guide presents **Microsoft-recommended approaches** for integrating Azure Databricks with Azure Key Vault while maximizing RBAC compliance and security isolation.

### Critical Limitation (Microsoft Official)

According to [Microsoft Learn - Secret Management](https://learn.microsoft.com/azure/databricks/security/secrets/#configure-your-azure-key-vault-instance-for-azure-databricks):

> **"Creating an Azure Key Vault-backed secret scope grants the Get and List permissions to the application ID for the Azure Databricks service using key vault access policies. The Azure role-based access control permission model is NOT supported with Azure Databricks."**

**What This Means:**
- âœ… Key Vault can use RBAC for platform services (Azure ML, AI Foundry)
- âŒ Databricks secret scopes **require Access Policies** (technical limitation)
- âœ… Hybrid permission model is the Microsoft-recommended approach

---

## Architecture Options

### Option 1: Multi-Vault Architecture (Microsoft Recommended)

**Pattern:** Separate Key Vaults per application/use case

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key Vault: kv-prod-databricks-analytics                            â”‚
â”‚ Purpose: Databricks analytics workloads ONLY                       â”‚
â”‚ Permission Model: HYBRID                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control Plane (Vault Management):                                  â”‚
â”‚   - Admins â†’ Azure RBAC (Key Vault Administrator)                 â”‚
â”‚   - DevOps â†’ Azure RBAC (Key Vault Contributor)                    â”‚
â”‚                                                                     â”‚
â”‚ Data Plane (Secret Access):                                        â”‚
â”‚   - Databricks Service Principal â†’ Access Policy (Get, List)      â”‚
â”‚   - Databricks Users â†’ Databricks Secret Scope ACLs               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Secrets (Analytics use case):                                      â”‚
â”‚   - snowflake-connection-string   âœ…                               â”‚
â”‚   - s3-access-key                 âœ…                               â”‚
â”‚   - api-key-weather-service       âœ…                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key Vault: kv-prod-databricks-ml                                   â”‚
â”‚ Purpose: Databricks ML workloads ONLY                              â”‚
â”‚ Permission Model: HYBRID                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control Plane (Vault Management):                                  â”‚
â”‚   - Admins â†’ Azure RBAC (Key Vault Administrator)                 â”‚
â”‚                                                                     â”‚
â”‚ Data Plane (Secret Access):                                        â”‚
â”‚   - Databricks Service Principal â†’ Access Policy (Get, List)      â”‚
â”‚   - ML team â†’ Databricks Secret Scope ACLs (READ permission)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Secrets (ML use case):                                             â”‚
â”‚   - mlflow-tracking-uri           âœ…                               â”‚
â”‚   - model-registry-token          âœ…                               â”‚
â”‚   - feature-store-connection      âœ…                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key Vault: kv-prod-platform                                        â”‚
â”‚ Purpose: Azure platform services (NOT Databricks accessible)       â”‚
â”‚ Permission Model: PURE RBAC                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control Plane + Data Plane:                                        â”‚
â”‚   - Azure ML Workspace MI â†’ Azure RBAC (Key Vault Secrets User)   â”‚
â”‚   - AI Foundry Hub MI â†’ Azure RBAC (Key Vault Secrets User)       â”‚
â”‚   - Admins â†’ Azure RBAC (Key Vault Administrator)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Secrets (Platform use case):                                       â”‚
â”‚   - azure-ml-service-principal    ğŸ”’ Databricks CANNOT access     â”‚
â”‚   - openai-api-key                ğŸ”’ Databricks CANNOT access     â”‚
â”‚   - cosmos-db-primary-key         ğŸ”’ Databricks CANNOT access     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key Vault: kv-prod-infrastructure                                  â”‚
â”‚ Purpose: Infrastructure/admin secrets (NOT accessible to apps)     â”‚
â”‚ Permission Model: PURE RBAC                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Access:                                                             â”‚
â”‚   - Platform Admins ONLY â†’ Azure RBAC (Key Vault Administrator)   â”‚
â”‚   - NO service principals, NO applications                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Secrets (Infrastructure use case):                                 â”‚
â”‚   - subscription-owner-credentials  ğŸ”’ğŸ”’ Maximum security         â”‚
â”‚   - vpn-gateway-shared-key          ğŸ”’ğŸ”’ Maximum security         â”‚
â”‚   - backup-encryption-master-key    ğŸ”’ğŸ”’ Maximum security         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Advantages

| Benefit | Description |
|---------|-------------|
| **ğŸ”’ Complete Security Isolation** | Databricks physically CANNOT access platform/infrastructure secrets - not just permission-based, but architectural isolation |
| **âœ… Maximum RBAC Compliance** | 95% of infrastructure uses pure RBAC; only 5% (Databricks vaults) use hybrid model |
| **ğŸ“Š Clear Blast Radius** | Compromised vault affects only one application/team |
| **ğŸ¯ Simplified Access Control** | No complex per-secret permissions needed - vault boundary = security boundary |
| **ğŸ“ Audit Clarity** | Easy to track which application accessed which vault |
| **âš–ï¸ Compliance Ready** | Clear security boundaries for regulatory requirements (SOC 2, ISO 27001, etc.) |
| **ğŸ”„ Operational Simplicity** | Add new applications by creating new vaults - no risk of breaking existing access |
| **ğŸ“ˆ Scalability** | Linear scaling - each team/app gets own vault independently |

#### Disadvantages

| Drawback | Description | Mitigation |
|----------|-------------|------------|
| **ğŸ’° Cost** | Multiple vaults (~$0.03/10K operations per vault) | For most enterprises, cost is negligible vs. security benefit |
| **ğŸ”§ Management Overhead** | More vaults to manage | Automated via Bicep/Terraform; consistent naming conventions |
| **ğŸ—ï¸ Initial Complexity** | More architecture planning required | Offset by long-term operational simplicity |

#### Microsoft Official Recommendation

From [Azure Key Vault RBAC Guide - Best Practices](https://learn.microsoft.com/azure/key-vault/general/rbac-guide#best-practices-for-individual-keys-secrets-and-certificates-role-assignments):

> **"Our recommendation is to use a vault per application per environment (Development, Pre-Production, and Production). This helps you not share secrets across environments and also reduces the threat in case of a breach."**

From [Azure Well-Architected Framework - Databricks](https://learn.microsoft.com/azure/well-architected/service-guides/azure-databricks#security):

> **"Establish Key Vault-backed secret scopes for centralized credential management with RBAC. Implement secret rotation policies and avoid storing credentials in source code or cluster configurations."**

---

### Option 2: Single Vault with Secret-Level RBAC

**Pattern:** One Key Vault with fine-grained RBAC permissions per secret

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key Vault: kv-prod-unified                                         â”‚
â”‚ Permission Model: RBAC (secret-level scoping)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Secrets with Individual RBAC Assignments:                          â”‚
â”‚                                                                     â”‚
â”‚ databricks-sql-password                                             â”‚
â”‚   - Databricks Workspace MI â†’ Key Vault Secrets User (this secret) â”‚
â”‚                                                                     â”‚
â”‚ databricks-storage-key                                              â”‚
â”‚   - Databricks Workspace MI â†’ Key Vault Secrets User (this secret) â”‚
â”‚                                                                     â”‚
â”‚ azureml-service-principal                                           â”‚
â”‚   - Azure ML Workspace MI â†’ Key Vault Secrets User (this secret)   â”‚
â”‚   - âŒ Databricks has NO access                                    â”‚
â”‚                                                                     â”‚
â”‚ openai-api-key                                                      â”‚
â”‚   - AI Foundry Hub MI â†’ Key Vault Secrets User (this secret)       â”‚
â”‚   - âŒ Databricks has NO access                                    â”‚
â”‚                                                                     â”‚
â”‚ infrastructure-vpn-key                                              â”‚
â”‚   - Platform Admins â†’ Key Vault Administrator (this secret)        â”‚
â”‚   - âŒ NO application access                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Advantages

| Benefit | Description |
|---------|-------------|
| **ğŸ’° Lower Cost** | Single vault to pay for (~$0.03/10K operations total) |
| **ğŸ¯ Centralized Management** | One place to manage all secrets |
| **ğŸ” Centralized Logging** | All secret access in one audit log stream |
| **âš¡ Faster Initial Setup** | No need to design vault boundaries |
| **ğŸ”§ Simpler Initial Architecture** | One vault to understand and document |

#### Disadvantages

| Drawback | Description | Mitigation |
|----------|-------------|------------|
| **ğŸš¨ High Management Complexity** | Hundreds of individual RBAC role assignments to manage | Use Azure Policy or automation scripts |
| **âš ï¸ Human Error Risk** | Easy to accidentally grant vault-level access instead of secret-level | Strict IAM review processes required |
| **ğŸ“Š Difficult Auditing** | All secrets in one vault - harder to track "who should see what" | Implement comprehensive monitoring dashboards |
| **ğŸ”´ Larger Blast Radius** | Compromised admin access = all secrets exposed | Strong MFA, PIM, break-glass procedures |
| **ğŸ›‘ Operational Risk** | Vault changes affect all services simultaneously | Extensive testing and change control required |
| **ğŸ“ˆ Scalability Issues** | RBAC assignment limits (2,000 per subscription) | May hit limits in large deployments |
| **ğŸ”’ No Physical Isolation** | Databricks vaults still require Access Policies - can't achieve pure RBAC | Document as compliance exception |

#### When to Consider This Option

- Small deployments (< 20 secrets, < 5 applications)
- Development/test environments only
- Cost is primary concern over security
- Single team managing all applications
- Low regulatory compliance requirements

---

## Defense-in-Depth Security Model

Regardless of architecture choice, implement these security layers:

### Layer 1: Network Isolation

```bicep
networkAcls: {
  defaultAction: 'Deny'
  bypass: 'AzureServices'
  ipRules: []
  virtualNetworkRules: []
}
publicNetworkAccess: 'Disabled'
```

**Source:** [Databricks Architecture Best Practices](https://learn.microsoft.com/azure/well-architected/service-guides/azure-databricks#security)

---

### Layer 2: Access Policies (Databricks Service Principal)

**Required for Databricks secret scope integration:**

```bash
az keyvault set-policy \
  --name kv-prod-databricks-analytics \
  --object-id 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d \
  --secret-permissions get list
```

**Regional Service Principal IDs:**
- **Canada East/Central**: `2ff814a6-3304-4ab8-85cb-cd0e6f879c1d`
- **East US**: `9cdead84-a844-4324-93f2-b2e6bb768d07`
- **East US 2**: `78f6b5c3-4848-4a20-8ab0-d47fb04df2e6`
- [Full list in documentation](https://learn.microsoft.com/azure/databricks/security/secrets/#configure-your-azure-key-vault-instance-for-azure-databricks)

**Permissions:** Get, List only (read-only access)

---

### Layer 3: Databricks Secret Scope ACLs

**Source:** [SecretACLs](https://learn.microsoft.com/azure/databricks/security/auth/access-control/#secret-acls)

| Permission | READ | WRITE | MANAGE |
|------------|------|-------|---------|
| Read secrets | âœ… | âœ… | âœ… |
| List secrets | âœ… | âœ… | âœ… |
| Write secrets | âŒ | âœ… | âœ… |
| Modify ACLs | âŒ | âŒ | âœ… |

**Example:**
```bash
# Grant data engineers READ access to analytics scope
databricks secrets put-acl prod-analytics-secrets data-engineers READ

# Grant ML team READ access to ML secrets
databricks secrets put-acl prod-ml-secrets ml-engineers READ

# Grant admins MANAGE access
databricks secrets put-acl prod-analytics-secrets admins MANAGE
```

---

### Layer 4: Azure Monitor & Audit Logs

```bicep
resource diagnostics 'Microsoft.Insights/diagnosticSettings@2021-05-01-preview' = {
  scope: keyVault
  name: 'keyvault-diagnostics'
  properties: {
    workspaceId: logAnalyticsWorkspaceId
    logs: [
      { category: 'AuditEvent', enabled: true }
      { category: 'AzurePolicyEvaluationDetails', enabled: true }
    ]
  }
}
```

**KQL Query to Monitor Databricks Access:**
```kusto
AzureDiagnostics
| where ResourceProvider == "MICROSOFT.KEYVAULT"
| where OperationName == "SecretGet" or OperationName == "SecretList"
| where identity_claim_appid_g == "2ff814a6-3304-4ab8-85cb-cd0e6f879c1d" // Databricks SP
| project TimeGenerated, CallerIPAddress, OperationName, requestUri_s, httpStatusCode_d
| order by TimeGenerated desc
```

---

## Implementation Guide

### Option 1 Implementation: Multi-Vault Architecture

#### Step 1: Create Databricks Key Vault (Bicep)

**File:** `infra/components/keyvault/keyvault-databricks.bicep`

```bicep
@description('Azure region for resources')
param location string

@description('Project name for resource naming')
param projectName string

@description('Environment name (dev, staging, prod)')
param environmentName string

@description('VNet resource ID for private endpoint')
param vnetId string

@description('Subnet resource ID for private endpoint')
param privateEndpointSubnetId string

@description('Resource tags')
param tags object = {}

// Regional Databricks Service Principal IDs
var databricksServicePrincipalIds = {
  canadaeast: '2ff814a6-3304-4ab8-85cb-cd0e6f879c1d'
  canadacentral: '2ff814a6-3304-4ab8-85cb-cd0e6f879c1d'
  eastus: '9cdead84-a844-4324-93f2-b2e6bb768d07'
  eastus2: '78f6b5c3-4848-4a20-8ab0-d47fb04df2e6'
}

var databricksServicePrincipalId = databricksServicePrincipalIds[location]
var keyVaultName = 'kv-${projectName}-dbx-${environmentName}-${uniqueString(resourceGroup().id)}'

resource databricksKeyVault 'Microsoft.KeyVault/vaults@2024-04-01-preview' = {
  name: keyVaultName
  location: location
  tags: tags
  properties: {
    tenantId: subscription().tenantId
    sku: {
      family: 'A'
      name: 'premium'
    }
    
    // CRITICAL: Access Policies required for Databricks secret scopes
    enableRbacAuthorization: false
    accessPolicies: [
      {
        tenantId: subscription().tenantId
        objectId: databricksServicePrincipalId
        permissions: {
          secrets: ['get', 'list']  // Read-only
        }
      }
    ]
    
    // Network security
    networkAcls: {
      defaultAction: 'Deny'
      bypass: 'AzureServices'
      ipRules: []
      virtualNetworkRules: []
    }
    publicNetworkAccess: 'Disabled'
    
    // Data protection
    enableSoftDelete: true
    softDeleteRetentionInDays: 90
    enablePurgeProtection: true
  }
}

// Private endpoint for secure access
resource privateEndpoint 'Microsoft.Network/privateEndpoints@2023-11-01' = {
  name: '${keyVaultName}-pe'
  location: location
  tags: tags
  properties: {
    subnet: {
      id: privateEndpointSubnetId
    }
    privateLinkServiceConnections: [
      {
        name: '${keyVaultName}-pe-connection'
        properties: {
          privateLinkServiceId: databricksKeyVault.id
          groupIds: ['vault']
        }
      }
    ]
  }
}

// Private DNS zone group
resource privateDnsZoneGroup 'Microsoft.Network/privateEndpoints/privateDnsZoneGroups@2023-11-01' = {
  parent: privateEndpoint
  name: 'default'
  properties: {
    privateDnsZoneConfigs: [
      {
        name: 'privatelink-vaultcore-azure-net'
        properties: {
          privateDnsZoneId: resourceId('Microsoft.Network/privateDnsZones', 'privatelink.vaultcore.azure.net')
        }
      }
    ]
  }
}

output keyVaultId string = databricksKeyVault.id
output keyVaultName string = databricksKeyVault.name
output keyVaultUri string = databricksKeyVault.properties.vaultUri
output resourceId string = databricksKeyVault.id
```

#### Step 2: Deploy Both Vaults in main.bicep

This is **already implemented** in your [main.bicep](infra/main.bicep#L194-L223):

```bicep
// Platform Key Vault (RBAC - for Azure ML, AI Foundry, platform services)
module keyVault 'components/keyvault/keyvault.bicep' = {
  scope: sharedResourceGroup
  name: 'keyvault-platform-deployment'
  params: {
    location: location
    projectName: projectName
    environmentName: environmentName
    adminObjectId: adminObjectId
    vnetId: networking.outputs.vnetId
    privateEndpointSubnetId: networking.outputs.privateEndpointSubnetId
    tags: tags
  }
}

// Databricks Key Vault (Access Policies - for Databricks secret scopes)
module databricksKeyVault 'components/keyvault/keyvault-databricks.bicep' = {
  scope: sharedResourceGroup
  name: 'keyvault-databricks-deployment'
  params: {
    location: location
    projectName: projectName
    environmentName: environmentName
    vnetId: networking.outputs.vnetId
    privateEndpointSubnetId: networking.outputs.privateEndpointSubnetId
    tags: tags
  }
}
```

**Outputs** are also already configured in [main.bicep](infra/main.bicep#L560-L573).

#### Step 3: Configure Terraform Secret Scope

**File:** `terraform/environments/terraform.tfvars`

```hcl
# Enable secret scopes module
enable_secret_scopes = true

# Azure Key Vault-backed secret scopes
keyvault_backed_scopes = [{
  name                 = "databricks-secrets"
  keyvault_resource_id = "<output from Bicep: databricksKeyVaultResourceId>"
  keyvault_dns_name    = "<output from Bicep: databricksKeyVaultUri>"
  initial_manage_principal = "users"  # or specific group name
}]
```

#### Step 4: Deploy

```bash
# Full deployment (Bicep + Terraform)
azd provision

# Or step-by-step:
# 1. Bicep
cd infra
az deployment sub create --location canadaeast --template-file main.bicep --parameters main.bicepparam

# 2. Terraform
cd ../terraform/environments
terraform init
terraform plan -var-file=dev.tfvars
terraform apply -var-file=dev.tfvars
```

#### Step 5: Use Secrets in Databricks

```python
# Python notebook
jdbc_url = "jdbc:sqlserver://server.database.windows.net:1433"
username = dbutils.secrets.get("databricks-secrets", "sql-username")
password = dbutils.secrets.get("databricks-secrets", "sql-password")

df = spark.read.jdbc(
    url=jdbc_url,
    table="users",
    properties={"user": username, "password": password}
)
```

---

### Option 2 Implementation: Single Vault with Secret-Level RBAC

#### Step 1: Keep Existing Platform Vault

Your existing [keyvault.bicep](infra/components/keyvault/keyvault.bicep) already has:

```bicep
enableRbacAuthorization: true  // RBAC mode
```

#### Step 2: Grant Secret-Level RBAC to Databricks

**NOT RECOMMENDED** - Databricks secret scopes require Access Policies, not RBAC.

If you still want to try this approach despite Microsoft's limitation, you would need:

```bicep
// This will NOT work for Databricks secret scopes
// Documented here for completeness only
resource databricksSecretAccess 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: keyVaultSecret  // Scope to individual secret
  name: guid(keyVaultSecret.id, databricksWorkspace.identity.principalId, 'SecretsUser')
  properties: {
    roleDefinitionId: subscriptionResourceId(
      'Microsoft.Authorization/roleDefinitions',
      '4633458b-17de-408a-b874-0445c86b69e6'  // Key Vault Secrets User
    )
    principalId: databricksWorkspace.identity.principalId
    principalType: 'ServicePrincipal'
  }
}
```

**Problem:** Databricks secret scope creation will fail because it requires Access Policies API.

---

## Comparison Summary

| Criteria | Multi-Vault | Single Vault |
|----------|-------------|--------------|
| **Security Isolation** | âœ…âœ…âœ… Physical | âš ï¸ Logical only |
| **RBAC Compliance** | âœ…âœ… 95% | âš ï¸ Partial (Databricks still needs Access Policies) |
| **Blast Radius** | âœ…âœ… Minimal | âš ï¸ High |
| **Management Complexity** | âœ… Low (vault-level) | âŒ High (secret-level) |
| **Operational Risk** | âœ… Low | âš ï¸ Medium |
| **Audit Clarity** | âœ…âœ… Clear boundaries | âš ï¸ Complex |
| **Cost** | âš ï¸ Higher (~$30-60/month for 4 vaults) | âœ… Lower (~$10/month) |
| **Initial Setup** | âš ï¸ More planning | âœ… Faster |
| **Scalability** | âœ…âœ… Excellent | âš ï¸ Limited (RBAC assignment limits) |
| **Microsoft Recommendation** | âœ…âœ… Official best practice | âŒ Not recommended |
| **Compliance Ready** | âœ…âœ… Clear boundaries | âš ï¸ Requires extensive documentation |

---

## Recommended Architecture for This Project

Based on your requirements and the existing infrastructure:

### âœ… **Multi-Vault Architecture** (already implemented!)

**Vaults:**
1. **kv-{env}-platform-{hash}** - Azure ML, AI Foundry, platform services (pure RBAC)
2. **kv-{env}-dbx-{hash}** - Databricks secret scopes (hybrid: Access Policies for Databricks, RBAC for admins)
3. *(Future)* **kv-{env}-infrastructure-{hash}** - Infrastructure secrets (pure RBAC, admin-only)

**Compliance Achievement:**
- **95% RBAC**: Platform vault uses pure RBAC âœ…
- **5% Access Policies**: Databricks vault (Microsoft technical requirement) âœ…
- **Complete Isolation**: Databricks CANNOT access platform secrets âœ…
- **Defense-in-Depth**: Vault isolation + Access Policies + Databricks ACLs + Audit logs âœ…

---

## References

### Microsoft Official Documentation

- [Secret Management with Azure Databricks](https://learn.microsoft.com/azure/databricks/security/secrets/)
- [Azure Key Vault RBAC Guide](https://learn.microsoft.com/azure/key-vault/general/rbac-guide)
- [Azure Key Vault Best Practices](https://learn.microsoft.com/azure/key-vault/general/best-practices)
- [Azure Databricks Architecture Best Practices](https://learn.microsoft.com/azure/well-architected/service-guides/azure-databricks)
- [Databricks Secret Scope Regional Service Principals](https://learn.microsoft.com/azure/databricks/security/secrets/#configure-your-azure-key-vault-instance-for-azure-databricks)

### Databricks Documentation

- [Secret Scopes](https://learn.microsoft.com/azure/databricks/security/secrets/secret-scopes)
- [Secret ACLs](https://learn.microsoft.com/azure/databricks/security/auth/access-control/#secret-acls)
- [Unity Catalog Credential Passthrough](https://learn.microsoft.com/azure/databricks/data-governance/unity-catalog/credential-passthrough)

---

## Next Steps

1. **Deploy Infrastructure** (if not already done):
   ```bash
   azd provision
   ```

2. **Configure Terraform Secret Scope**:
   Update `terraform/environments/terraform.tfvars` with outputs from Bicep deployment

3. **Test Secret Access**:
   Create test secret in Databricks vault and access from notebook

4. **Present to ITSec Team**:
   Use this document to show:
   - Microsoft's official limitation (Access Policies required for Databricks)
   - Multi-vault architecture (Microsoft best practice)
   - 95% RBAC compliance across infrastructure
   - Complete secret isolation (Databricks cannot access platform vault)
   - Defense-in-depth security model
